# Asset uploader

TODO
Test, Run and Build info
Add echo test
Add bonus points to README
review README

## How to Build:

## Endpoints
### POST ​​/asset  
* **Description**:  
Creates a new asset with a random uuid and returns a url to put the asset

* **Body**:  
empty  

* **Response**:  
```
{
"upload_url":​​"<s3-signed-url-for-upload>", ​​"id":​​"<asset-id>"
}
```
Response code | Description
------------ | -------------
201 | Asset created
500 | Internal Error


* **Technical Notes**:  
  * **Metadata file:**  
This endpoint creates a metadata file in the path metadata/assetId.  
In this metadata file we keep the expiration date and expiration offset, we will need this info in the **PUT ​​/asset/<asset-id>** endpoint  
Since the 
[S3 consistency model](https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel
)
supports read-after-write consistency, that is (only): put and get same object.  
When the PUT /asset/assetID checks that metadata, it should be ok to read.  
However, a malicious user can still try to auto generate uuids and query the api so we lose the 
read-after-write consistency, because we will have a write-after-read -> eventual consistency.
 
  * **POST to s3:**  
  The original problem statement ask for a url which can be used by a post directly to s3.
  Even a post query can be made to s3, it´s intended for [browser upload.](https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-authentication-HTTPPOST.html)
   
    So, when trying to do a post to a bucket/assetId with query params auth, it fails:
  ```bash
     https://assertuploader.s3.eu-west-1.amazonaws.com/a79b143e-6218-450b-a8e8-18d00d788b8b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIASWEEC46WNIHR44WH%2F20190510%2Feu-west-1%2Fs3%2Faws4_request&X-Amz-Date=20190510T204051Z&X-Amz-Expires=900&X-Amz-SignedHeaders=host&X-Amz-Signature=3df259f4cacbf54a157673c67b285b71ff28ae3d01df52b59d203c9af01fba59
  ```
  
   ```xml
    <?xml version="1.0" encoding="UTF-8"?>
    <Error>
        <Code>MethodNotAllowed</Code>
        <Message>The specified method is not allowed against this resource.</Message>
        <Method>POST</Method>
        <ResourceType>OBJECT</ResourceType>
        <RequestId>A6BC66C6E743C2BA</RequestId>
        <HostId>jvYsrZh9D3cdDPgoVe8MuiVunH5HfPIiWU0L8MW8NAUG462w/YHiG1reg4OrMNjowYBX5gPvOgA=</HostId>
    </Error>
   ```
  
  Similarly, query string authentication is not supported for POST. 
  ````bash
  https://assertuploader.s3.eu-west-1.amazonaws.com/?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIASWEEC46WNIHR44WH%2F20190510%2Feu-west-1%2Fs3%2Faws4_request&X-Amz-Date=20190510T201100Z&X-Amz-Expires=900&X-Amz-SignedHeaders=host&X-Amz-Signature=35b37b840d2e5a68f0716fa66aef10405ad788311367b2fe82b9b7baa133552a
  ````
  ```xml
  <?xml version="1.0" encoding="UTF-8"?>
  <Error>
      <Code>InvalidArgument</Code>
      <Message>Query String Parameters not allowed on POST requests.</Message>
      <ArgumentName>X-Amz-SignedHeaders</ArgumentName>
      <ArgumentValue>null</ArgumentValue>
      <RequestId>B15BD091C3F46199</RequestId>
      <HostId>VEyCIjFNnAB94JgiTXQtInRkVyXFbe4d5QwY80wctbrh5UYzNSOo8WEWRYo2trA1m0j0LIToCvg=</HostId>
  </Error>
  ````
  
  So, [we need to use a put](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/s3-example-presigned-urls.html), not a post, with the url returned

  * **POST correctness:**  
    As explained [here](https://stackoverflow.com/questions/630453/put-vs-post-in-rest), a post is more intended when we don´t know the id of the new resource and a put when we know it.  
    In our case, the asset id is generated by the POST /asset endpoint. So, conceptually, to me, a put to s3 seems more adecuated than a post
  
  * **Metadata path:**  
  Since all marker files are inside metadata/ it´s worth to read:
[No prefix considerations for s3 anymore](https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/)   

### PUT ​​/asset/<asset-id>  
* **Description:** 
Will mark the upload operation as completed. Eventually, by default after 1 minute

* **Body:** 
```
{ ​​​"Status":​​"uploaded" }
```  

* **Response:**  
Empty

Response code | Description
------------ | -------------
201 | Query accepted
400 | If the body is incorrect
404 | If the asset id is not found
500 | Internal Error


* **Technical Notes**:  
This is the tricky endpoint:
Since the user can put the asset again as long as the signed url is valid.
We need to make sure we mark the correct file and it don´t get overwrited.  
There is several approaches here:
* Update status no matter if the put to s3 has expired or not.  
This will allow the user to mark the file as completed, but it can be overwrited. From that point, beahviour might be unexpected depending of the implementation.  
One example: the version marked as uploaded can get deleted by an overwrite, so, we will get a version which is not matching what the user marked as uploaded.  
Another one: its marked as completed, we got the get link, then its overwrited. What happens now?

For this reason,this endpoint schedule a task to mark the asset 
once the expiration time as elapsed. 
That explains the 201 and not a 200 as successful response code


### GET ​​/asset/<asset-id>  
* **Description:**   
Will get a signed s3 url for getting the object

* **Response:**  
```
{ ​​​"Download_url":​​"<s3-signed-url-for-upload>" } 
```

Response code | Description
------------ | -------------
200 | Query succeed
404 | If the asset id is not found
500 | Internal Error


* **Technical Notes:**  
In the PUT ​​/asset/<asset-id> endpoint we mark the asset as completed. 
This is done with a tag in the metadata object. Since tags are eventually consistent,
it might take a bit longer after the object is marked as uploaded. But, since the ### PUT ​​/asset/<asset-id> 
is async, it does not matter.

## Why only s3?
I tried to keep only one datastore, if we need to deal with a metadata store and s3,  the sync issues between the two that might occur are difficult to trak for a simple app like this one.  
At some point, we might not avoid the need for a metadata store, as new features comes in.  
If that occurs, one possible solution is to use some event drive architecture: like  [saga](https://microservices.io/patterns/data/saga.html) pattern


## Project Layout
Following pkg, cmd and build patterns as seen here
https://github.com/golang-standards/project-layout

## Vendoring
Dep is used for vendoring
https://golang.github.io/dep/


## AWS SDK
https://docs.aws.amazon.com/sdk-for-go/api/service/s3/










